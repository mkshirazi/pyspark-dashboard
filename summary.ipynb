{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/10 22:27:31 WARN Utils: Your hostname, scslt388 resolves to a loopback address: 127.0.1.1; using 192.168.2.19 instead (on interface wlp0s20f3)\n",
      "21/12/10 22:27:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/10 22:27:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "21/12/10 22:27:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/12/10 22:27:34 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "21/12/10 22:27:34 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/mmkshira/spark-3.2.0-bin-hadoop2.7\"\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(appName=\"YourTest\", master=\"local[*]\")\n",
    "# sc = SparkContext(\"local\", \"test-app\")\n",
    "# from pyspark.sql import SQLContext\n",
    "# sqlContext = SQLContext(sc)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import random\n",
    "\n",
    "spark = SparkSession.builder.appName(\"YourTest\").master(\"local[2]\").config('spark.ui.port', random.randrange(4000,5000)).getOrCreate()\n",
    "\n",
    "### importing libraries\n",
    "#json\n",
    "# import jsonlines\n",
    "#spark\n",
    "from pyspark.sql.functions import explode,col\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import concat_ws\n",
    "#plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "# matplotlib and wordcloud\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "#dash\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output \n",
    "# numerical computing\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8PW_w5V3Hub",
    "outputId": "5e24b714-6165-444e-b48e-28ff5045dab6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/10 22:27:49 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.json(\"sample.jsonl\").sort(\"year\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = data.select(\"id\",\"papertitle\",\"authors\",\"year\",\"citationcount\",\"topics\",\"language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+----------+-------------+--------------------+\n",
      "|        id|          papertitle|             authors|      year|citationcount|              topics|\n",
      "+----------+--------------------+--------------------+----------+-------------+--------------------+\n",
      "|2960426479|secure distribute...|[{University of S...|2020-01-01|            3|[computer vision,...|\n",
      "|2930137557|a poor man s appr...|[{Technical Unive...|2020-01-01|            2|[finite element m...|\n",
      "|2919403121|filtering techniq...|[{Northumbria Uni...|2020-01-01|            2|[data mining, fea...|\n",
      "|2996755977|sign opt a query ...|[{IBM (United Sta...|2020-01-01|            3|[directional deri...|\n",
      "|2954810543|a real time image...|[{Jiangnan Univer...|2020-01-01|            1|[kernel, computer...|\n",
      "|2946528256|discrete multiobj...|[{Malaviya Nation...|2020-01-01|            1|[telecommunicatio...|\n",
      "|2996197041|emerging frontier...|[{Philips (Finlan...|2020-01-01|            1|[knowledge manage...|\n",
      "|2998899284|comparing rule ba...|[{University of T...|2020-01-01|            1|[privacy law, con...|\n",
      "|2972050955|machine learning ...|[{University of S...|2020-01-01|            2|[overfitting, res...|\n",
      "|2918628604|performance analy...|[{Jadavpur Univer...|2020-01-01|            1|[efficient energy...|\n",
      "|2962739952|multi objective p...|[{null, null, nul...|2020-01-01|            2|[particle swarm o...|\n",
      "|2995289095|distinct patterns...|[{Dalian Universi...|2020-01-01|            1|[speech comprehen...|\n",
      "|2999691331|joint learning se...|[{National Yunlin...|2020-01-01|            1|[feature fusion, ...|\n",
      "|2896798184|an evolutionary c...|[{University of L...|2020-01-01|            1|[cluster analysis...|\n",
      "|2906729185|group maximum dif...|[{University of W...|2020-01-01|            9|[sample space, ph...|\n",
      "|3000537141|twin timescale ra...|[{Beijing Univers...|2020-01-01|            1|[base station, co...|\n",
      "|3003820956|a machine conscio...|[{Technical Unive...|2020-01-01|            2|[architecture, co...|\n",
      "|2984067768|flow of hybrid na...|[{Kuvempu Univers...|2020-01-01|            3|[mechanics, compu...|\n",
      "|2951627131|tbi2flow travel b...|[{Dalian Universi...|2020-01-01|            3|[taxis, flow, glo...|\n",
      "|3002033136|energy efficient ...|[{University of W...|2020-01-01|            1|[efficient energy...|\n",
      "+----------+--------------------+--------------------+----------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "142140\n",
      "33478\n",
      "3942\n",
      "109\n"
     ]
    }
   ],
   "source": [
    "n_papers = summary.count()\n",
    "n_languages = summary.select(\"language\").distinct().count()\n",
    "n_authors = summary.select(explode(\"authors\").alias(\"author\"))\\\n",
    "        .select(F.col(\"author\").getItem(\"id\").alias(\"author_id\")).distinct().count()\n",
    "n_topics = summary.select(explode(\"topics\").alias(\"topic\"))\\\n",
    "        .select(\"topic\").distinct().count()\n",
    "n_institutes = summary.select(explode(\"authors\").alias(\"author\"))\\\n",
    "        .select(F.col(\"author\").getItem(\"affiliation\").alias(\"affiliation\")).distinct().count()\n",
    "\n",
    "\n",
    "print(n_papers)\n",
    "print(n_authors)\n",
    "print(n_topics)\n",
    "print(n_institutes)\n",
    "print(n_languages)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
